<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">    
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Dr. Jinmeng WU's Homepage</title>

    <!-- Le styles -->
    <link href="bootstrap.css" rel="stylesheet">
    <style type="text/css">
      body {
        padding-top: 20px;
        padding-bottom: 60px;
      }
	  
	  .foot-fixed-bottom {
 bottom: 0;
 display: block;
 left: 0;
 margin-bottom: 0;
 position: fixed;
 right: 0;
 z-index: 1030;
 background-color: rgba(130, 130, 130, 0.8);
}
.foot-fixed-bottom hr {
 border-image: none;
 border-style: solid none;
 border-width: 1px 0;
 margin: 0 0 5px;
 width: 100%;
}
.foot-fixed-bottom p {
 color: rgb(255, 255, 255);
 font-size: 14px;
 margin: 0 12px 15px;
}

      /* Custom container */
      .container {
        margin: 0 auto;
        max-width: 1000px;
      }
      .container > hr {
        margin: 60px 0;
      }

      /* Main marketing message and sign up button */
      .jumbotron {
        margin: 80px 0;
        text-align: center;
      }
      .jumbotron h1 {
        font-size: 100px;
        line-height: 1;
      }
      .jumbotron .lead {
        font-size: 24px;
        line-height: 1.25;
      }
      .jumbotron .btn {
        font-size: 21px;
        padding: 14px 24px;
      }

      /* Supporting marketing content */
      .marketing {
        margin: 60px 0;
      }
      .marketing p + h4 {
        margin-top: 28px;
      }


      /* Customize the navbar links to be fill the entire space of the .navbar */
      .navbar .navbar-inner {
        padding: 0;
      }
      .navbar .nav {
        margin: 0;
        display: table;
        width: 100%;
      }
      .navbar .nav li {
        display: table-cell;
        width: 1%;
        float: none;
      }
      .navbar .nav li a {
        font-weight: bold;
        text-align: center;
        border-left: 1px solid rgba(255,255,255,.75);
        border-right: 1px solid rgba(0,0,0,.1);
      }
      .navbar .nav li:first-child a {
        border-left: 0;
        border-radius: 3px 0 0 3px;
      }
      .navbar .nav li:last-child a {
        border-right: 0;
        border-radius: 0 3px 3px 0;
      }
    </style>
    <link href="bootstrap-responsive.css" rel="stylesheet">

    
  </head>

  <body>

    

      <div class="masthead">
        <h3 class="muted"></h3>
        <div class="navbar navbar-fixed-top">
          <div class="navbar-inner">
            <div class="container">
              <ul class="nav">
                <li><a href="#">Home</a></li>
                <li><a href="#bio">Short Bio</a></li>
                <!--<li><a href="#Download">Download</a></li>-->
                <li><a href="#Project">Project</a></li>                
                <li><a href="#Award">Award</a></li>                
                <li><a href="#Publication">Publication</a></li>                
              </ul>
            </div>
          </div>
        </div><!-- /.navbar -->
      </div>

      <div class="container">
	      <br><br>
		  <div class="bs-docs-grid ">
	 
	  	  <div class="media">
		    <a class="pull-left">
			    <img src="mengmeng.jpg" height="500" width="260" class="media-object" >
			</a>
			<div class="media-body">			
			<h4>Dr. Jinmeng Wu (吴锦梦博士)</h4>
			<!--<h5>Ph.D in Computer Science <a href="./cv.pdf">(CV)</a></h5>-->
			<h5>Ph.D in Computer Science</h5>
      <a href="https://www.semanticscholar.org/author/Jinmeng-Wu/92959364" >Semantic Scholar</a><br>

			<!--Video Retrieval Group <a href="http://vireo.cs.cityu.edu.hk/">(VIREO)</a><br>-->
			School of Electrical Engineering and Computer Science<br>			
			University of Liverpool<br>
      <br><br>
			<i>Email: jinmeng2004910 AT outlook DOT com</i>			
			 
		 </div></div>
		 
		 <a id= "bio"></a>
		 <hr>
		 <div class="row">	
		 <div class="span">
				<h4>Short Bio</h4>
				Jinmeng Wu received Ph.D degree from <a href="https://www.liverpool.ac.uk/">University of Liverpool</a>, supervised by <a href="https://scholar.google.co.uk/citations?user=pYnXjN4AAAAJ&hl=en">Prof. Yannis Goulermas</a>. 
        She visited <a href="https://www.manchester.ac.uk/">University of Manchester</a>, under supervision of <a href="https://personalpages.manchester.ac.uk/staff/tingting.mu/Site/About_Me.html">Dr. Tingting Mu </a>.
				She received the B.S. degree from <a href="https://www.liverpool.ac.uk/">University of Liverpool</a> (2014), as the First-Class Honor.
				
				<br> <br>
				Her research interest lies in Natural Language Processing (NLP). She serves as reviewer for AAAI 2023.
		 </div>
		 </div>
		 <!--	
		 <a id= "Download"></a>
		 <hr>
		 <div class="row">	
		 <div class="span">
				<h4>Download</h4>
				<ul>
				<li><b><a
                    href="http://vireo.cs.cityu.edu.hk/vireoweb81"><u>VIREO-WEB81</u></a>
                    concept detectors, features and detection scores on
                    NUS-WIDE dataset</b> <br>
                    We are pleased to release 81 semantic concept detectors
                    trained on the NUS-WIDE training dataset, and their
                    detection scores on NUS-WIDE testing dataset. Global and
                    local features (BoW) are also available.</li> 
				</ul>
		 </div>
		 </div>
		 -->
		 <a id= "Project"></a>
		 <hr>
		 <div class="row">	
		 <div class="span">
				<h4>Project</h4>
		<li><b>Research on Multiple Attention Visual Q&A Technology Based on ProblemReasoning</b>, Innovation Fund of Hubei Province, 12/2022-11/2023
		<li><b>Semantic Matching Technology for Smart Open Domain Search</b>, ResearchInitiation Fund, 01/2020 -12/2022
		<li><b>Research on Key Technologies for Real Time 3D Multi object Detection Based onIntelligent Monitoring of Unmanned Boats</b>, Hubei Province NSFC, 09/2021-10/2021
    </li>

		 <a id= "Award"></a>
		 <hr>
		 <div class="row">	
		 <div class="span">
				<h4>Award</h4>
    <li><b>Best Ph.D. Poster 2016 for Outstanding presentation</b><a target="_blank"
                    href=""><img
                    border="0" src="" align="top"></a><br>
                    University of Liverpool, First Place, International Academic Award, 2016. (1/1)
                    <br>
                    <br>
    </li>
    <li><b>Fluid process state detection technology and industrial application of intelligent control system</b><a target="_blank"
                    href=""><img
                    border="0" src="" align="top"></a><br>
                    China Petroleum and Chemical Automation Application Association,
                    <i><b>First Prize </b></i>of Science and Technology Progress Award, 2023. (8/14)
                    <br>
                    <br>
    </li>

    <li><b>Road Indication All-day 3D Real-time Measurement Technology and Industrial Application</b><a target="_blank"
                    href=""><img
                    border="0" src="" align="top"></a><br>
                    Chinese Instrumentation Society, 
                    <i><b>Second Prize</b></i> of Science and TechnologyProgress Award, 2022-11-01. (8/14)
                    <br>
                    <br>
    </li>

    <li><b>Advanced Methods and Industrialization Applications of Image Processing</b><a target="_blank"
                    href=""><img
                    border="0" src="" align="top"></a><br>
                    ChineseSociety of Automation, <i><b>First Prize</b></i> of Science and Technology Progress Award, 2022-01-08. (12/14)
                    <br>
                    <br>
    </li>

    <li><b>Automatic detection method and industrial application of intelligent control technologyfor petrochemical pipeline gas leakage</b><a target="_blank"
                    href=""><img
                    border="0" src="" align="top"></a><br>
                    Chinese Society of Automation,
                    <i><b>Second Prize</i></b> of Science and Technology Progress Award, 2020-11-06. (14/14)
                    <br>
                    <br>
    </li>




		 <a id= "Publication"></a>
		 <hr>
		 <div class="row">	
		 <div class="span">
				<h4>Publication</h4>
				<h5><i>Journal Paper(* corresponding author)</i></h5>
				<ul>


		<li><b>Memory-aware Attentive Control for Community Question Answering with Knowledge-based Dual Refinement</b><a target="_blank"
                    href="https://ieeexplore.ieee.org/document/10025020"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>J. M. Wu</b></i>, T. T. Mu, J. Thiyagalingam, J. Y. Goulermas*, 
                    IEEE Transactions on Systems, Man, and Cybernetics: Systems (2023).
                    <br><br>
    </li>

    <li><b>Iterative Semantic Transformer by Greedy Distillation for Community Question Answering</b><a target="_blank"
                    href=""><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>J. M. Wu</b></i>, T. T. Mu, H. Y. Hong, J. Thiyagalingam, Y. B. Hao, T. X. Zhang, J. Y. Goulermas*, 
                    IEEE Transaction on Audio, Speech and Language Processing, 2023, Under Revision
                    <br><br>
    </li>

    <li><b>Question-aware Dynamic Scene Graph of Local Semantic Representation Learning for Visual Question Answering</b><a target="_blank"
                    href="https://www.sciencedirect.com/science/article/abs/pii/S0167865523001216"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>J. M. Wu</b></i>, F. L. Ge, H. Y. Hong*, Y. Shi, Y. B. Hao, L. Ma, 
                    Pattern Recognition Letters 170 (2023): 93-99.
                    <br><br>
    </li>
    
    <li><b>Word-level Dual Channel with Multi-heads Semantic Attention</b><a target="_blank"
                    href="https://www.aimspress.com/article/doi/10.3934/era.2023306"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>J. M. Wu</b></i>, H. Y. Hong, Y. Z. Zhang*, Y. B. Hao, L. Ma, L. Wang, 
                    Electronic Research Archive 31.10 (2023): 6012-6026. 
                    <br><br>
    </li>
    
    <li><b>A real-time critical part detection for the blurred image of infrared reconnaissance balloon with boundary curvature feature analysis</b><a target="_blank"
                    href="https://link.springer.com/article/10.1007/s11554-020-00997-6"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    H. Y. Hong, J. W. Shi, Z. Y. Liu, Y. Z. Zhang, <i><b>J. M. Wu</b></i>,
                    Journal of Real-Time Image Processing, 2021, 18(3): 619-634.
                    <br><br>
    </li>     

    <li><b>Building Interactive Sentence-aware Representation based on Generative Language Model for Question Answering</b><a target="_blank"
                    href="https://www.sciencedirect.com/science/article/abs/pii/S092523122030031X"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>J. M. Wu</b></i>, T. T. Mu, J. Thiyagalingam and J. Y. Goulermas*, 
                    Neurocomputing，ELSEVIER,389(2020):93-107.
                    <br><br>
    </li>     

    <li><b>PolSAR-SSN: An End-to-end Superpixel Sampling Network for PolSAR Image Classification</b><a target="_blank"
                    href="https://ieeexplore.ieee.org/document/9717257"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    L. Wang, H. Y. Hong, Y. Z. Zhang, <i><b>J. M. Wu</b></i>, L. Ma, Y. Zhu, 
                    IEEE Geoscience and Remote Sensing Letters, 2022, 19: 1-5.
                    <br><br>
    </li>    


    <li><b>Attention in Attention: Modeling Context Correlation for Efficient Video Classification</b><a target="_blank"
                    href="https://arxiv.org/pdf/2204.09303.pdf"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    Y. B. Hao, S. Wang, P. Cao, X. J. Gao, T. Xu, <i><b>J. M. Wu</b></i>, X. N. He, 
                     IEEE Transactions on Circuits and Systems for Video Technology, 2022, 32(10): 7120-7132.
                    <br><br>
    </li>    

    <li><b>Correlation Filtering Based Hashing for Fine-grained Image Retrieval</b><a target="_blank"
                    href="https://ieeexplore.ieee.org/document/9265245"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                   L. Ma, X. Li, Y. Shi, L. Wang <i><b>J. M. Wu</b></i>, Z. H. Huang, Y. Z. Zhang, 
                   IEEE Signal Processing Letters, 2020, 27: 2129-2133.
                    <br><br>
    </li>    
  
    <li><b>Learning discrete class-specific prototypes for deep semantic hashing</b><a target="_blank"
                    href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221003131"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                   L. Ma, X. Li, Y. Shi, L. K. Huang, Z. H. Huang, <i><b>J. M. Wu</b></i>, 
                  Neurocomputing, 2021, 443: 85-95.
                    <br><br>
    </li> 

    <li><b>Blind natural image deblurring with edge preservation based on L0-regularized gradient prior</b><a target="_blank"
                    href="https://www.sciencedirect.com/science/article/abs/pii/S0030402620315631"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                   Y. Z. Zhang, Y. Shi, L. Ma, <i><b>J. M. Wu</b></i>, L. Wang, H. Y. Hong, 
                   Optik, 2021, 225: 165735.
                    <br><br>
    </li> 


    <li><b>Non-uniform Noise Removal Method for Non-cooperative Mine Target Images</b><a target="_blank"
                    href=""><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                   H. Y. Hong, S. K. Wu, Y. Shi, <i><b>J. M. Wu</b></i>, C. S. Sun, et. al, 
                  Infrared and Laser Engineering. Description, 2021, 50(3): 20200344-1-20200344-10.
                    <br><br>
    </li> 
    </ul>
		<h5><i>Conference Paper</i></h5>
		<ul>

    <li><b>Unsupervised Encoder-Decoder Model for Anomaly Prediction Task</b><a target="_blank"
                    href="https://link.springer.com/chapter/10.1007/978-3-031-27818-1_45"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>J. M. Wu</b></i>, P. C. Shu, H. Y. Hong, X. X. Li, L. Ma, Y. Z. Zhang, Y. Zhu, L. Ma, 
                    International Conference on Multimedia Modeling. Cham: Springer Nature Switzerland, 2023: 549-561.
                    <br><br>
    </li>

    <li><b>Question-Driven Multiple Attention (DQMA) Model for Visual Question Answer</b><a target="_blank"
                    href="https://ieeexplore.ieee.org/document/9930294"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>J. M. Wu</b></i>, F. L. Ge, L. Ma, Y. B. Hao, P. C. Shu, 
                    IEEE 2022 International Conference on Artificial Intelligence and Computer Information Technology (AICIT), 2022, doi: 10.1109/AICIT55386.2022.9930294, pp. 1-4.
                    <br><br>
    </li>									

    <li><b>Cross-sentence pre-trained model for Interactive QA matching</b><a target="_blank"
                    href="https://aclanthology.org/2020.lrec-1.666/"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>J. M. Wu</b></i>, Y. B. Hao, 
                    Proceedings of the 12th Language Resources and Evaluation Conference. 2020.
                    <br><br>
    </li>     

<li><b>Community Question Answering Using Context-aware Bi-directional LSTM with Interactive Attention System</b><a target="_blank"
                    href=""><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    <i><b>J. M. Wu</b></i>, T. T. Mu, 
                    Proceedings of the 25th WiML Workshop track in Annual Conference on Neural Information Processing, 2017.
                    <br><br>
    </li>    

<li><b>How Contrastive Pre-training Benefits Audio-Visual Segmentation? A Study from Supervised and Zero-shot Perspective</b><a target="_blank"
                    href=""><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                    J. R. Yu, H. R. Li, Y. B. Hao, <i><b>J. M. Wu</b></i>, T. Xu, S. Wang, X. N. He, BMVC, 2023, Accepted.
                    <br><br>
    </li>    

    <li><b>The Intelligent Preparation of Scene Matching Guidance Reference Map Based on Prior Knowledge</b><a target="_blank"
                    href="https://ieeexplore.ieee.org/document/9299729"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                   P. Chen, Y. Z. Zhang, <i><b>J. M. Wu</b></i>, X. X. Li, 
                   Proceedings of The 12th International Conference on Wireless Communications and Signal Processing, IEEE, pp.159-163, 10.1109/WCSP49889.2020.9299729, 2020.
                    <br><br>
    </li> 

    <li><b>Realization of Detection Algorithms for Key Parts of Unmanned Aerial Vehicles Based on Deep Learning</b><a target="_blank"
                    href="https://ieeexplore.ieee.org/document/9299682"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                   G. Y. Wang, H. Y. Hong, Y. Z. Zhang, <i><b>J. M. Wu</b></i>, Y. F. Wang, 
                   Proceedings of The 12th International Conference on Wireless Communications and Signal Processing, Nanjing, IEEE, pp.137-142, 2020.
                    <br><br>
    </li> 


    <li><b>Identification and extraction of circular markers in 3D reconstruction</b><a target="_blank"
                    href="https://ieeexplore.ieee.org/document/9299768"><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                   Y. F. Wang, H. Y. Hong, <i><b>J. M. Wu</b></i>, G. Y. Wang, S. Y. Li, 
                   Proceedings of The 12th International Conference on Wireless Communications and Signal Processing, IEEE, pp.213-216，October 21, 2020.
    </li> 

    <li><b>Natural Language Processing and Java Implementation[M]</b><a target="_blank"
                    href=""><img
                    border="0" src="./pdf.bmp" align="top"></a><br>
                   L. Gang, <i><b>J. M. Wu</b></i>, G. Y. Wang, S. Y. Li, 
                   People's Posts and Telecommunications Press, ISBN 978-7-115-52507-9, 638 thousand words, 2020.


    <!--
		<li><b>Research on Key Technologies for Real Time 3D Multi object Detection Based on Intelligent Monitoring of Unmanned Boats</b><br>
		    <i><b>Leader</b></i>, Hubei Provincial Natural Science Foundation, 09/2021-10/2021.
                    <br>
                    <br>
    </li>
    -->
					
				</ul>
		 </div>
		 </div>

		 <hr>
		  
      </div></div> <!-- /container -->
      <div class="foot-fixed-bottom">
	  	      <p align = "right"><a href= "http://twitter.github.com/bootstrap/"><u><font color="#000000">Proudly powered by Bootstrap</font></u></a></p>
      </div>
     



    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../assets/js/jquery.js"></script>
    <script src="../assets/js/bootstrap-transition.js"></script>
    <script src="../assets/js/bootstrap-alert.js"></script>
    <script src="../assets/js/bootstrap-modal.js"></script>
    <script src="../assets/js/bootstrap-dropdown.js"></script>
    <script src="../assets/js/bootstrap-scrollspy.js"></script>
    <script src="../assets/js/bootstrap-tab.js"></script>
    <script src="../assets/js/bootstrap-tooltip.js"></script>
    <script src="../assets/js/bootstrap-popover.js"></script>
    <script src="../assets/js/bootstrap-button.js"></script>
    <script src="../assets/js/bootstrap-collapse.js"></script>
    <script src="../assets/js/bootstrap-carousel.js"></script>
    <script src="../assets/js/bootstrap-typeahead.js"></script>

  </body>
</html>
